<!DOCTYPE html>
<html>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
    
    
        
            
                <link rel="shortcut icon" href="/images/favicon.ico">
            
        
        
            
                <link rel="icon" type="image/png" href="/images/favicon-192x192.png" sizes="192x192">
            
        
        
            
                <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
            
        
    
    <!-- title -->
    <title>『CS228笔记』Inference ── Sampling methods（五）</title>
    <!-- styles -->
    
<link rel="stylesheet" href="/css/style.css">

    <link href="https://fonts.googleapis.com/css?family=Noto+Sans+SC&display=swap" rel="stylesheet">
    <link href="https://cdn.jsdelivr.net/gh/tonsky/FiraCode@2/distr/fira_code.css" rel="stylesheet">
    <!-- rss -->
    
    
<meta name="generator" content="Hexo 4.2.0"></head>

<body class="max-width mx-auto px3 ltr">

    <div id="header-post">
    <a id="menu-icon" href="#"><i class="fas fa-bars fa-lg"></i></a>
    <a id="menu-icon-tablet" href="#"><i class="fas fa-bars fa-lg"></i></a>
    <a id="top-icon-tablet" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i
                class="fas fa-chevron-up fa-lg"></i></a>
    <span id="menu">
    <span id="nav">
      <ul>
          
              <li><a href="/">Home</a></li>
          
              <li><a href="/archives/">Articles</a></li>
          
              <li><a href="/category/">Category</a></li>
          
              <li><a href="/tags/">Tag</a></li>
          
              <li><a href="/about/">About</a></li>
          
              <li><a href="/search/">Search</a></li>
          
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
          
          
              <li><a class="icon" href="/2020/05/11/cs228_representation_bayesian_networks/"><i class="fas fa-chevron-right"
                                                                           aria-hidden="true"
                                                                           onmouseover="$('#i-next').toggle();"
                                                                           onmouseout="$('#i-next').toggle();"></i></a></li>
          
          <li><a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i
                          class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();"
                          onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" href="#"><i class="fas fa-share-alt" aria-hidden="true"
                                        onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();"
                                        onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
    <li><a class="icon"
           href="https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url=http://blog.tsinghua2018.top/2020/05/15/cs228_inference_sampling_based/&title=『CS228笔记』Inference ── Sampling methods（五）"><i
                    class="fab fa-qq " aria-hidden="true"></i></a></li>
    <li><a class="icon"
           href="https://service.weibo.com/share/share.php?url=http://blog.tsinghua2018.top/2020/05/15/cs228_inference_sampling_based/&title=『CS228笔记』Inference ── Sampling methods（五）"><i
                    class="fab fa-weibo " aria-hidden="true"></i></a></li>
    <li><a class="icon" href="https://twitter.com/share?url=http://blog.tsinghua2018.top/2020/05/15/cs228_inference_sampling_based/&text=『CS228笔记』Inference ── Sampling methods（五）" target="_blank" rel="noopener"><i
                    class="fab fa-twitter " aria-hidden="true"></i></a></li>
    <li><a class="icon" href="mailto:?subject=『CS228笔记』Inference ── Sampling methods（五）&body=Check out this article: http://blog.tsinghua2018.top/2020/05/15/cs228_inference_sampling_based/"><i
                    class="fas fa-envelope " aria-hidden="true"></i></a></li>
</ul>
    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#sampling-from-a-probability-distribution"><span class="toc-number">1.</span> <span class="toc-text">Sampling from a probability distribution</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#forward-sampling"><span class="toc-number">1.1.</span> <span class="toc-text">Forward Sampling</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#monte-carlo-estimation"><span class="toc-number">2.</span> <span class="toc-text">Monte Carlo estimation</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#rejection-sampling"><span class="toc-number">2.1.</span> <span class="toc-text">Rejection sampling</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#importance-sampling"><span class="toc-number">2.2.</span> <span class="toc-text">Importance sampling</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#normalized-importance-sampling"><span class="toc-number">2.3.</span> <span class="toc-text">Normalized importance sampling</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#markov-chain-monte-carlo"><span class="toc-number">3.</span> <span class="toc-text">Markov chain Monte Carlo</span></a></li></ol>
    </div>
  </span>
</div>

<div class="content index py4">
    
    <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
    <header>
        
    <h1 class="posttitle" itemprop="name headline">
        『CS228笔记』Inference ── Sampling methods（五）
    </h1>

        <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">
            David
            
        </span>
      </span>
            
    <div class="postdate">
        
            <time datetime="2020-05-15T07:03:59.000Z"
                  itemprop="datePublished">2020-05-15</time>
            
        
    </div>

            
            
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link" href="/tags/CS228%E7%AC%94%E8%AE%B0/" rel="tag">CS228笔记</a>
    </div>

        </div>
    </header>
    
    <div class="content" itemprop="articleBody">
        <blockquote>
<p>以下内容翻译自 <a href="https://ermongroup.github.io/cs228-notes/" target="_blank" rel="noopener">CS228 课程</a>。</p>
</blockquote>
<p>在实践中，我们使用的概率模型通常非常复杂，像变量消除这样简单的算法可能太慢了。实际上，许多有趣的模型可能根本不接受精确的多项式时间复杂度的解，因此，机器学习方面的大量研究工作都花在了开发推理问题近似解的算法上。本节开始研究此类算法。</p>
<p>存在两种主要的近似算法：将推理表述为最优化问题的变分方法，以及通过从感兴趣的分布中重复生成随机数来产生答案的采样方法。</p>
<blockquote>
<p>变分推理方法的名称来源于变分演算，变分演算将其他函数作为参数，并进行优化。</p>
</blockquote>
<p>采样方法可用于执行边际和 MAP 推理查询，此外，它们可以计算各种有趣的数值，例如根据给定的概率模型计算随机变量分布的期望 <span class="math inline">\(E[f(X)]\)</span>。过去，采样方法一直是执行近似推理的主要方法，尽管在过去 15 年中，变分方法已经成为可行的（并且通常是更好的）替代方法。</p>
<h2 id="sampling-from-a-probability-distribution">Sampling from a probability distribution</h2>
<p>作为热身，让我们考虑一下，如何从具有 <span class="math inline">\(k\)</span> 个可能结果和对应概率 <span class="math inline">\(\theta_1, \cdots, \theta_k\)</span> 的多项式分布中进行采样。</p>
<p>通常，采样不是一个容易的问题。我们的计算机只能从非常简单的分布（例如 <span class="math inline">\([0, 1]\)</span> 上的均匀分布）生成样本。所有采样技术都涉及以巧妙的方式多次调用某种简单的子例程。</p>
<blockquote>
<p>即使这样，那些样本也不是真正随机的。它们实际上是从确定性序列中获取的，该确定性序列的统计属性（例如平均值）与真正随机的统计属性是无法区分的。我们称此类序列为伪随机。</p>
</blockquote>
<p>在我们的例子中，可以通过将单位间隔分为 <span class="math inline">\(k\)</span> 个区域，其中区域 <span class="math inline">\(i\)</span> 的大小为 <span class="math inline">\(\theta_i\)</span>。然后，我们从 <span class="math inline">\([0,1]\)</span> 中均匀采样，并返回样本所在区域的值。</p>
<p><img src="https://ermongroup.github.io/cs228-notes/assets/img/multinomial-sampling.png" /></p>
<h3 id="forward-sampling">Forward Sampling</h3>
<blockquote>
<p>TODO：待修改</p>
</blockquote>
<p>我们通过多项式采样的技术通过称为祖先（或正向）采样的方法自然地扩展到具有多项式变量的贝叶斯网络。给定贝叶斯网络指定的概率p（x1，…，xn），我们按拓扑顺序对变量进行采样。我们从没有父母的情况下对变量进行采样开始；然后我们通过将这些变量的CPD调整为第一步所采样的值来从下一代采样。我们这样进行直到所有n个变量都被采样为止。重要的是，在n个变量的贝叶斯网络中，正向采样使我们能够通过从每个CPD中精确获取1个多项式样本，以线性O（n）时间从联合分布x〜p（x）进行采样</p>
<p>在我们较早的学生成绩模型中，我们将首先对考试难度d'和智力水平i'进行抽样。然后，一旦有了样本d'和i'，我们就会从p（g∣d'，i'）生成学生等级g'。在每一步中，我们仅执行标准多项式采样。</p>
<p>如果模型可以由在每个节点上具有少量变量的集团树表示，则也可以在无向模型上有效执行“正向采样”。校准集团树，这将使我们在每个节点上都有边际分布，并选择一个节点作为根。然后，对根节点中的变量进行边际化以获取单个变量的边际。一旦已经从根节点对单个变量x1〜p（X1∣E = e）的边际进行了采样，则可以将新采样的值X1 = x1作为证据。完成将来自同一节点的其他变量采样，每次合并新采样的节点作为证据，即x2〜p（X2 = x2∣X1 = x1，E = e）和x3〜p（X3 = x3∣X1 = x1， X2 = x2，E = e），依此类推。当向下移动树以从其他节点采样变量时，每个节点必须发送包含采样变量值的更新消息。</p>
<h2 id="monte-carlo-estimation">Monte Carlo estimation</h2>
<p>从分布中采样使我们能够执行许多有用的任务，包括边际和 MAP 推断，以及计算如下形式的积分： <span class="math display">\[
\mathbb{E}_{x \sim p}[f(x)]=\sum_{x} f(x) p(x)
\]</span></p>
<blockquote>
<p><span class="math inline">\(f(x)\)</span> 表示 <span class="math inline">\(x\)</span> 的分布，<span class="math inline">\(p(x)\)</span> 是 <span class="math inline">\(x\)</span> 的概率。</p>
</blockquote>
<p>如果 <span class="math inline">\(f(x)\)</span> 不具有与 <span class="math inline">\(p\)</span> 的贝叶斯网络结构匹配的特殊结构，则该积分将无法进行分析；相反，我们将使用来自 <span class="math inline">\(p\)</span> 的样本对其进行近似。根据给定分布中的大量样本构造解决方案的算法称为蒙特卡洛方法（Monte Carlo, MC）。</p>
<p>蒙特卡洛积分是通用蒙特卡洛原理的重要实例。这项技术可以用来估算目标期望值： <span class="math display">\[
\mathbb{E}_{x \sim p}[f(x)] \approx I_{T}=\frac{1}{T} \sum_{t=1}^{T} f\left(x^{t}\right)
\]</span> 其中，<span class="math inline">\(x^1, \cdots, x^T\)</span> 是根据 <span class="math inline">\(p\)</span> 抽取的样本。可以表述为： <span class="math display">\[
\begin{aligned}
\mathbb{E}_{x^{1}, \ldots, x^{T} \stackrel{\mathrm{i.d}}, p}{\sim}\left[I_{T}\right] &amp;=\mathbb{E}_{x \sim p}[f(x)] \\
\operatorname{Var}_{x^{1}, \ldots, x^{T} \sim \ldots, p}\left[I_{T}\right] &amp;=\frac{1}{T} \operatorname{Var}_{x \sim p}[f(x)]
\end{aligned}
\]</span> 第一个等式表示 MC 估计 <span class="math inline">\(I_{T}\)</span> 是 <span class="math inline">\(\mathbb{E}_{x \sim p}[f(x)]\)</span> 的无偏估计；两个等式共同表示当 <span class="math inline">\(T \to \infty\)</span> 时，<span class="math inline">\(I_T \to \mathbb{E}_{x \sim p}[f(x)]\)</span>。特别当我们有足够多的样本时，<span class="math inline">\(I_T\)</span> 的方差可以变得任意小。</p>
<h3 id="rejection-sampling">Rejection sampling</h3>
<p>蒙特卡洛积分的一个特例是拒绝采样。我们可以使用它来计算区域 <span class="math inline">\(R\)</span> 的面积，方法是在已知的较大面积区域中进行采样，并记录落入 <span class="math inline">\(R\)</span> 内的样本所占的比例。</p>
<h3 id="importance-sampling">Importance sampling</h3>
<p>不幸的是，拒绝采样可能会非常浪费。若 <span class="math inline">\(p(E=e)\)</span> 的概率仅有 1%，那么我们会丢弃剩余的 99% 的样本。</p>
<p>一种计算此类积分更好地方法是重要性采样。其主要思想是从分布 <span class="math inline">\(q\)</span>（希望 <span class="math inline">\(q(x)\)</span> 与 <span class="math inline">\(f(x)\cdot p(x)\)</span> 成正比）进行采样，然后以某种准则重新衡量样本，以便使它们的总和仍近似于所需的积分。</p>
<p>更正式地说法是，假设我们想计算 <span class="math inline">\(\mathbb{E}_{x \sim p}[f(x)]\)</span>，我们可以重写积分： <span class="math display">\[
\begin{aligned}
\mathbb{E}_{x \sim p}[f(x)] &amp;=\sum_{x} f(x) p(x) \\
&amp;=\sum_{x} f(x) \frac{p(x)}{q(x)} q(x) \\
&amp;=\mathbb{E}_{x \sim q}[f(x) w(x)] \\
&amp; \approx \frac{1}{T} \sum_{t=1}^{T} f\left(x^{t}\right) w\left(x^{t}\right)
\end{aligned}
\]</span> 其中，<span class="math inline">\(w(x)=\frac{p(x)}{q(x)}\)</span> 和样本 <span class="math inline">\(x^t\)</span> 都从分布 <span class="math inline">\(q\)</span> 进行采样。换句话说，我们转而从分布 <span class="math inline">\(q\)</span> 中进行采样，并且用 <span class="math inline">\(w(x)\)</span> 重新衡量，所得蒙特卡洛近似的期望值将会是原始的积分。</p>
<p>新估计方法的方差为： <span class="math display">\[
\operatorname{Var}_{x \sim q}[f(x) w(x)]=\mathbb{E}_{x \sim q}\left[f^{2}(x) w^{2}(x)\right]-\mathbb{E}_{x \sim q}[f(x) w(x)]^{2} \geq 0
\]</span> 我们可以通过让 <span class="math inline">\(q(x)=\frac{|f(x)| p(x)}{\int|f(x)| p(x) d x}\)</span> 来让方差为零。如果我们可以从这个 <span class="math inline">\(q\)</span> 采样（并评估相应的权重），那我们只需要一个蒙特卡洛样本就可以计算积分的真实值。当然，从这样的 <span class="math inline">\(q\)</span> 中进行采样通常是 NP 困难的（其分母 <span class="math inline">\(\mathbb{E}_{x \sim p}[|f(x)|]\)</span> 基本上是我们首先要估计的数量），但这至少给了我们一个方向。</p>
<p>在我们之前的例子中，我们要计算 <span class="math inline">\(p(E=e)\)</span>，我们可以让 <span class="math inline">\(q\)</span> 为均匀分布，然后使用如下的重要性采样： <span class="math display">\[
\begin{aligned}
p(E=e) &amp;=\mathbb{E}_{z \sim p}[p(e | z)] \\
&amp;=\mathbb{E}_{z \sim q}\left[p(e | z) \frac{p(z)}{q(z)}\right] \\
&amp;=\mathbb{E}_{z \sim q}\left[\frac{p(e, z)}{q(z)}\right] \\
&amp;=\mathbb{E}_{z \sim q}\left[w_{e}(z)\right] \\
&amp; \approx \frac{1}{T} \sum_{t=1}^{T} w_{e}\left(z^{t}\right)
\end{aligned}
\]</span> 其中，<span class="math inline">\(w_e(z)=\frac{p(e, z)}{q(z)}\)</span>。与拒绝分布不同，该方法会使用所有的样本。若 <span class="math inline">\(p(z|e)\)</span> 与均匀分布相差不大，则在非常少的样本后，它将收敛到真实概率。</p>
<h3 id="normalized-importance-sampling">Normalized importance sampling</h3>
<p>不幸的是，未归一化的重要性抽样不适用于估计形式的条件概率： <span class="math display">\[
P\left(X_{i}=x_{i} | E=e\right)=\frac{P\left(X_{i}=x_{i}, E=e\right)}{P(E=e)}
\]</span> 使用未归一化的重要性抽样，我们可以估计分子为： <span class="math display">\[
\begin{aligned}
P\left(X_{i}=x_{i}, E=e\right) &amp;=\sum_{z} \delta(z) p(e, z) \\
&amp;=\sum_{z} \delta(z) w_{e}(z) q(z) \\
&amp;=\mathbb{E}_{z \sim q}\left[\delta(z) w_{e}(z)\right] \\
&amp; \approx \frac{1}{T} \sum_{t=1}^{T} \delta\left(z^{t}\right) w_{e}\left(z^{t}\right)
\end{aligned}
\]</span> 其中，<span class="math inline">\(\delta(z)=\left\{\begin{array}{ll}1 &amp; \text { if } z \text { is consistent with } X_{i}=x_{i} \\ 0 &amp; \text { otherwise }\end{array}\right.\)</span>，分母和我们之前的推导一样： <span class="math display">\[
\begin{aligned}
p(E=e) &amp; \approx \frac{1}{T} \sum_{t=1}^{T} w_{e}\left(z^{t}\right)
\end{aligned}
\]</span> 如果我们用 <span class="math inline">\(z^{t} \sim q\)</span> 中的不同且独立的样本来估计分子 <span class="math inline">\(P\left(X_{i}=x_{i}, E=e\right)\)</span> 和分母 <span class="math inline">\(p(E=e)\)</span>，则这两个近似中的误差可能会加在一起。例如，如果对分子是低估，而对分母是高估，则最终概率可能是严重的低估。</p>
<p>但是，如果我们对分子和分母都使用相同的一组 <span class="math inline">\(T\)</span> 个样本 <span class="math inline">\(z^1, \cdots, z^T \sim q\)</span>，则可以避免这种复合误差问题。因此，归一化重要性采样的最终形式是： <span class="math display">\[
\hat{P}\left(X_{i}=x_{i} | E=e\right)=\frac{\frac{1}{T} \sum_{t=1}^{T} \delta\left(z^{t}\right) w_{e}\left(z^{t}\right)}{\frac{1}{T} \sum_{t=1}^{T} w_{e}\left(z^{t}\right)}
\]</span> 不幸的是，归一化重要性抽样估计器有一个缺点，那就是它有偏差。如果 <span class="math inline">\(T=1\)</span>，那么我们有： <span class="math display">\[
\mathbb{E}_{z \sim q}\left[\hat{P}\left(X_{i}=x_{i} | E=e\right)\right]=\mathbb{E}_{z \sim q}[\delta(z)] \neq P\left(X_{i}=x_{i} | E=e\right)
\]</span> 幸运的是，由于分子和分母都是无偏的，因此归一化重要性抽样估计量在渐近上仍然是无偏的，这意味着： <span class="math display">\[
\lim _{T \rightarrow \infty} \mathbb{E}_{z \sim q}\left[\hat{P}\left(X_{i}=x_{i} | E=e\right)\right]=P\left(X_{i}=x_{i} | E=e\right)
\]</span></p>
<h2 id="markov-chain-monte-carlo">Markov chain Monte Carlo</h2>

    </div>
</article>

    
        <div id="footer-post-container">
    <div id="footer-post">

        <div id="nav-footer" style="display: none">
            <ul>
                
                    <li><a href="/">Home</a></li>
                
                    <li><a href="/archives/">Articles</a></li>
                
                    <li><a href="/category/">Category</a></li>
                
                    <li><a href="/tags/">Tag</a></li>
                
                    <li><a href="/about/">About</a></li>
                
                    <li><a href="/search/">Search</a></li>
                
            </ul>
        </div>

        <div id="toc-footer" style="display: none">
            <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#sampling-from-a-probability-distribution"><span class="toc-number">1.</span> <span class="toc-text">Sampling from a probability distribution</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#forward-sampling"><span class="toc-number">1.1.</span> <span class="toc-text">Forward Sampling</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#monte-carlo-estimation"><span class="toc-number">2.</span> <span class="toc-text">Monte Carlo estimation</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#rejection-sampling"><span class="toc-number">2.1.</span> <span class="toc-text">Rejection sampling</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#importance-sampling"><span class="toc-number">2.2.</span> <span class="toc-text">Importance sampling</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#normalized-importance-sampling"><span class="toc-number">2.3.</span> <span class="toc-text">Normalized importance sampling</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#markov-chain-monte-carlo"><span class="toc-number">3.</span> <span class="toc-text">Markov chain Monte Carlo</span></a></li></ol>
        </div>

        <div id="share-footer" style="display: none">
            <ul>
    <li><a class="icon"
           href="https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url=http://blog.tsinghua2018.top/2020/05/15/cs228_inference_sampling_based/&title=『CS228笔记』Inference ── Sampling methods（五）"><i
                    class="fab fa-qq fa-lg" aria-hidden="true"></i></a></li>
    <li><a class="icon"
           href="https://service.weibo.com/share/share.php?url=http://blog.tsinghua2018.top/2020/05/15/cs228_inference_sampling_based/&title=『CS228笔记』Inference ── Sampling methods（五）"><i
                    class="fab fa-weibo fa-lg" aria-hidden="true"></i></a></li>
    <li><a class="icon" href="https://twitter.com/share?url=http://blog.tsinghua2018.top/2020/05/15/cs228_inference_sampling_based/&text=『CS228笔记』Inference ── Sampling methods（五）" target="_blank" rel="noopener"><i
                    class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
    <li><a class="icon" href="mailto:?subject=『CS228笔记』Inference ── Sampling methods（五）&body=Check out this article: http://blog.tsinghua2018.top/2020/05/15/cs228_inference_sampling_based/"><i
                    class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
</ul>
        </div>

        <div id="actions-footer">
            <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i
                        class="fas fa-bars fa-lg"
                        aria-hidden="true"></i> Menu</a>
            <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i
                        class="fas fa-list fa-lg"
                        aria-hidden="true"></i> TOC</a>
            <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i
                        class="fas fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
            <a id="top" style="display:none" class="icon" href="#"
               onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg"
                                                                               aria-hidden="true"></i> Top
            </a>
        </div>

    </div>
</div>
    
    <footer id="footer">
    <div class="footer-left">
        Copyright &copy; 2020 <i class="fas fa-heart"></i>
        David
        
    </div>
    <!-- <div class="footer-right">
    <nav>
      <ul>
        
        <li><a href="/">Home</a></li>
        
        <li><a href="/archives/">Articles</a></li>
        
        <li><a href="/category/">Category</a></li>
        
        <li><a href="/tags/">Tag</a></li>
        
        <li><a href="/about/">About</a></li>
        
        <li><a href="/search/">Search</a></li>
        
      </ul>
    </nav>
  </div> -->

    <div class="footer-custom">
        Framework by <a href="https://hexo.io" target="_blank">Hexo</a> & Theme by <a
                href="https://github.com/xuthus5/hexo-theme-cactus" target="_blank">Cactus-CN</a>
        
    </div>
</footer>
</div>
<!-- styles -->

<link rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/5.12.1/css/all.min.css">


<link rel="stylesheet" href="https://cdn.staticfile.org/justifiedGallery/3.7.0/css/justifiedGallery.min.css">

<!-- jquery -->

<script src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js"></script>


<script src="https://cdn.staticfile.org/justifiedGallery/3.7.0/js/jquery.justifiedGallery.min.js"></script>

<!-- clipboard -->

    
<script src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js"></script>

    <script type="text/javascript">
        $(function () {
            // copy-btn HTML
            var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
            btn += '<i class="far fa-clone"></i>';
            btn += '</span>';
            // mount it!
            $(".highlight .code pre").before(btn);
            var clip = new ClipboardJS('.btn-copy', {
                target: function (trigger) {
                    return trigger.nextElementSibling;
                }
            });
            clip.on('success', function (e) {
                e.trigger.setAttribute('aria-label', "Copied!");
                e.clearSelection();
            })
        })
    </script>


<script src="/js/main.js"></script>

<!-- search -->


    

        

        
            <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css" crossorigin="anonymous">
            <script defer src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js" crossorigin="anonymous"></script>
            <script
                    defer
                    src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/auto-render.min.js"
                    crossorigin="anonymous"
                    onload="renderMathInElement(document.body)">
            </script>
        

    

</body>

</html>