<!DOCTYPE html>
<html>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="这篇 paper 提出了一种基于变分自编码器（Variational Auto-Encoder, VAE）的无监督异常检测算法 Donut，对于来自一家顶级互联网公司的 KPI 数据可以获得 0.75~0.9 的最佳 F1 得分。 背景介绍 关键性能指标（Key Performance Indicators, KPI）是时间序列数据，用于测量诸如页面浏览量、用户在线数量、订单数量等等。在这些 KP">
<meta property="og:type" content="article">
<meta property="og:title" content="『阅读笔记』Unsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal KPIs inWeb Applications">
<meta property="og:url" content="http://blog.tsinghua2018.top/2020/04/26/www18_donut/index.html">
<meta property="og:site_name" content="David&#39;s Blog">
<meta property="og:description" content="这篇 paper 提出了一种基于变分自编码器（Variational Auto-Encoder, VAE）的无监督异常检测算法 Donut，对于来自一家顶级互联网公司的 KPI 数据可以获得 0.75~0.9 的最佳 F1 得分。 背景介绍 关键性能指标（Key Performance Indicators, KPI）是时间序列数据，用于测量诸如页面浏览量、用户在线数量、订单数量等等。在这些 KP">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/davidlight2018/figure_bed/img/2020-04-26_23-02-05.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/davidlight2018/figure_bed/img/2020-04-27_16-48-36.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/davidlight2018/figure_bed/img/2020-04-27_17-07-44.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/davidlight2018/figure_bed/img/2020-04-27_17-13-23.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/davidlight2018/figure_bed/img/2020-04-28_10-53-49.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/davidlight2018/figure_bed/img/2020-04-28_13-46-51.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/davidlight2018/figure_bed/img/2020-04-28_14-13-12.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/davidlight2018/figure_bed/img/2020-05-09_14-40-43.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/davidlight2018/figure_bed/img/2020-05-09_15-21-15.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/davidlight2018/figure_bed/img/2020-05-09_16-25-48.png">
<meta property="og:image" content="http://blog.tsinghua2018.top/Users/david/Library/Application%20Support/typora-user-images/image-20200509164754783.png">
<meta property="article:published_time" content="2020-04-26T10:45:48.000Z">
<meta property="article:modified_time" content="2020-05-09T09:34:59.451Z">
<meta property="article:author" content="David">
<meta property="article:tag" content="AIOps">
<meta property="article:tag" content="异常检测">
<meta property="article:tag" content="论文阅读">
<meta property="article:tag" content="无监督">
<meta property="article:tag" content="VAE">
<meta property="article:tag" content="变分自编码器">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/davidlight2018/figure_bed/img/2020-04-26_23-02-05.png">
    
    
        
          
              <link rel="shortcut icon" href="/images/favicon.ico">
          
        
        
          
            <link rel="icon" type="image/png" href="/images/favicon-192x192.png" sizes="192x192">
          
        
        
          
            <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
          
        
    
    <!-- title -->
    <title>『阅读笔记』Unsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal KPIs inWeb Applications</title>
    <!-- styles -->
    
<link rel="stylesheet" href="/css/style.css">

    <!-- persian styles -->
    
      
<link rel="stylesheet" href="/css/rtl.css">

    
    <!-- rss -->
    
    
<meta name="generator" content="Hexo 4.2.0"></head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/tags/">Tags</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/search/">Search</a></li>
        
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        
        <li><a class="icon" href="/2020/04/24/cvpr07_saliency_detection/"><i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" href="#"><i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" href="http://www.facebook.com/sharer.php?u=http://blog.tsinghua2018.top/2020/04/26/www18_donut/" target="_blank" rel="noopener"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://twitter.com/share?url=http://blog.tsinghua2018.top/2020/04/26/www18_donut/&text=『阅读笔记』Unsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal KPIs inWeb Applications" target="_blank" rel="noopener"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.linkedin.com/shareArticle?url=http://blog.tsinghua2018.top/2020/04/26/www18_donut/&title=『阅读笔记』Unsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal KPIs inWeb Applications" target="_blank" rel="noopener"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=http://blog.tsinghua2018.top/2020/04/26/www18_donut/&is_video=false&description=『阅读笔记』Unsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal KPIs inWeb Applications" target="_blank" rel="noopener"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=『阅读笔记』Unsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal KPIs inWeb Applications&body=Check out this article: http://blog.tsinghua2018.top/2020/04/26/www18_donut/"><i class="fas fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://getpocket.com/save?url=http://blog.tsinghua2018.top/2020/04/26/www18_donut/&title=『阅读笔记』Unsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal KPIs inWeb Applications" target="_blank" rel="noopener"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://reddit.com/submit?url=http://blog.tsinghua2018.top/2020/04/26/www18_donut/&title=『阅读笔记』Unsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal KPIs inWeb Applications" target="_blank" rel="noopener"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.stumbleupon.com/submit?url=http://blog.tsinghua2018.top/2020/04/26/www18_donut/&title=『阅读笔记』Unsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal KPIs inWeb Applications" target="_blank" rel="noopener"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://digg.com/submit?url=http://blog.tsinghua2018.top/2020/04/26/www18_donut/&title=『阅读笔记』Unsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal KPIs inWeb Applications" target="_blank" rel="noopener"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.tumblr.com/share/link?url=http://blog.tsinghua2018.top/2020/04/26/www18_donut/&name=『阅读笔记』Unsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal KPIs inWeb Applications&description=" target="_blank" rel="noopener"><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://news.ycombinator.com/submitlink?u=http://blog.tsinghua2018.top/2020/04/26/www18_donut/&t=『阅读笔记』Unsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal KPIs inWeb Applications" target="_blank" rel="noopener"><i class="fab fa-hacker-news " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#背景介绍"><span class="toc-number">1.</span> <span class="toc-text">背景介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#变分自编码器简介"><span class="toc-number">2.</span> <span class="toc-text">变分自编码器简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#donut"><span class="toc-number">3.</span> <span class="toc-text">Donut</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#网络结构"><span class="toc-number">3.1.</span> <span class="toc-text">网络结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#训练"><span class="toc-number">3.2.</span> <span class="toc-text">训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#检测"><span class="toc-number">3.3.</span> <span class="toc-text">检测</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#实验评估"><span class="toc-number">4.</span> <span class="toc-text">实验评估</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#数据集"><span class="toc-number">4.1.</span> <span class="toc-text">数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#参数设置"><span class="toc-number">4.2.</span> <span class="toc-text">参数设置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#实验结果"><span class="toc-number">4.3.</span> <span class="toc-text">实验结果</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#分析"><span class="toc-number">5.</span> <span class="toc-text">分析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#kde-解释"><span class="toc-number">5.1.</span> <span class="toc-text">KDE 解释</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#时间梯度的原因"><span class="toc-number">5.2.</span> <span class="toc-text">时间梯度的原因</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#次优平衡"><span class="toc-number">5.3.</span> <span class="toc-text">次优平衡</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#reference"><span class="toc-number">6.</span> <span class="toc-text">Reference</span></a></li></ol>
    </div>
  </span>
</div>

    
    <div class="content index py4">
        
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        『阅读笔记』Unsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal KPIs inWeb Applications
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">David's Blog</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2020-04-26T10:45:48.000Z" itemprop="datePublished">2020-04-26</time>
        
      
    </div>


      

      
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link" href="/tags/AIOps/" rel="tag">AIOps</a>, <a class="tag-link" href="/tags/VAE/" rel="tag">VAE</a>, <a class="tag-link" href="/tags/%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8/" rel="tag">变分自编码器</a>, <a class="tag-link" href="/tags/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/" rel="tag">异常检测</a>, <a class="tag-link" href="/tags/%E6%97%A0%E7%9B%91%E7%9D%A3/" rel="tag">无监督</a>, <a class="tag-link" href="/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" rel="tag">论文阅读</a>
    </div>


    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <p>这篇 paper 提出了一种基于变分自编码器（Variational Auto-Encoder, VAE）的无监督异常检测算法 <em>Donut</em>，对于来自一家顶级互联网公司的 KPI 数据可以获得 0.75~0.9 的最佳 F1 得分。</p>
<h2 id="背景介绍">背景介绍</h2>
<p>关键性能指标（Key Performance Indicators, KPI）是时间序列数据，用于测量诸如页面浏览量、用户在线数量、订单数量等等。在这些 KPI 中，大多数是与业务相关的 KPI（也是本文关注的重点）。这些 KPI 受用户行为和日程安排的影响很大，因此大致有规律的季节性模式出现（例如每天/每周）。在每个重复周期中，KPI 曲线的形状并不会完全相同，因为用户行为可能随着时间变化。这种 KPI 模式可以被称作「具有局部差异的季节性 KPI」。另一类局部变化是随着时间增加的趋势，可以通过 Holt-Winters 和 时间序列分解（Time Series Decomposition）来确定。除非正确处理了这些局部变化，否则异常检测算法可能无法正常工作。</p>
<p>除了 KPI 形状的季节性变化和局部变化外，这些 KPI 上还存在噪声。我们认为在每个点上它们都是独立的零均值高斯。高斯噪声的精确值是没有意义的，因此我们仅关注这些噪声的统计数据，即噪声的方差。因此我们可以将季节性 KPI 的正常模式形式化为两种组合：(1) 具有局部变化的季节性模式；(2) 高斯噪声的统计数据。</p>
<p>我们使用「anomalies」来表示不遵循正常模式的纪录点（如突然的尖峰或骤降），而使用「abnormal」来同时表示「anomalies」和缺失点。</p>
<p><img src="https://cdn.jsdelivr.net/gh/davidlight2018/figure_bed/img/2020-04-26_23-02-05.png" style="zoom:40%;" /></p>
<p>可以将 KPI 异常检测的公式定义如下：对于任何时间 <span class="math inline">\(t\)</span>，给定历史观测值 <span class="math inline">\(x_{t-T+1}, \cdots, x_t\)</span>，确定该时间是否发生异常（以 <span class="math inline">\(y_t=1\)</span> 表示）。异常检测算法通常计算 <span class="math inline">\(y_t=1\)</span> 的概率值 <span class="math inline">\(p(y_t=1|x_{t-T+ 1, \cdots, x_t})\)</span>，而不是直接计算 <span class="math inline">\(y_t\)</span>。之后，操作员可以通过选择阈值来决定是否声明异常，即得分超过该阈值的数据点表示异常。</p>
<h2 id="变分自编码器简介">变分自编码器简介</h2>
<p>深度贝叶斯网路使用神经网络来表达变量之间的关系，因此它们不再局限于简单的分布簇，可以轻松地用于复杂的数据。在训练和预测中经常采用变分推理技术（Variational inference techniques），这是解决由神经网络得出的后验分布的有效方法。</p>
<p>VAE 是一个深层的贝叶斯网络，它对两个随机变量（潜在变量 <span class="math inline">\(z\)</span> 和可见变量 <span class="math inline">\(x\)</span>）之间的关系进行建模。首先为 <span class="math inline">\(z\)</span> 选择一个先验，通常是多元的正态高斯分布 <span class="math inline">\(\mathcal{N}(0,I)\)</span>。之后，从 <span class="math inline">\(p_{\theta} (x|z)\)</span> 中采样 <span class="math inline">\(x\)</span>，其中 <span class="math inline">\(p_{\theta} (x|z)\)</span> 是从参数 <span class="math inline">\(\theta\)</span> 的神经网络中得出的。<span class="math inline">\(p_{\theta} (x|z)\)</span> 的确切形式需要根据任务需求来确定。真实的后验 <span class="math inline">\(p_{\theta} (z|x)\)</span> 是解析方法难以解出的，但是对于训练而言必不可少，并且在预测中有作用。因此，变分推理技术可用于拟合另一个神经网络作为后验 <span class="math inline">\(q_{\phi} (z|x)\)</span> 的近似。该后验通常假定为 <span class="math inline">\(\mathcal{N}\left(\boldsymbol{\mu}_{\phi}(\mathbf{x}), \boldsymbol{\sigma}_{\phi}^{2}(\mathbf{x})\right)\)</span> ，其中 <span class="math inline">\(\mu_{\phi}(\mathbf{x})\)</span> 和 <span class="math inline">\({\sigma}_{\phi}(\mathbf{x})\)</span> 都是从神经网络推出的。</p>
<p><img src="https://cdn.jsdelivr.net/gh/davidlight2018/figure_bed/img/2020-04-27_16-48-36.png" style="zoom:40%;" /></p>
<p>SGVB 是一种变分推理算法，通常与 VAE 一起使用，通过最大化证据下界 <span class="math inline">\(\text{ELBO}\)</span> 来联合近似的后验模型和生成模型，如下式所述。 <span class="math display">\[
\begin{aligned}
\log p_{\theta}(\mathbf{x}) &amp; \geq \log p_{\theta}(\mathbf{x})-\mathrm{KL}\left[q_{\phi}(\mathbf{z} | \mathbf{x}) \| p_{\theta}(\mathbf{z} | \mathbf{x})\right] \\
&amp;=\mathcal{L}(\mathbf{x}) \\
&amp;=\mathbb{E}_{q_{\phi}(\mathbf{z} | \mathbf{x})}\left[\log p_{\theta}(\mathbf{x})+\log p_{\theta}(\mathbf{z} | \mathbf{x})-\log q_{\phi}(\mathbf{z} | \mathbf{x})\right] \\
&amp;=\mathbb{E}_{q_{\phi}(\mathbf{z} | \mathbf{x})}\left[\log p_{\theta}(\mathbf{x}, \mathbf{z})-\log q_{\phi}(\mathbf{z} | \mathbf{x})\right] \\
&amp;=\mathbb{E}_{q_{\phi}(\mathbf{z} | \mathbf{x})}\left[\log p_{\theta}(\mathbf{x} | \mathbf{z})+\log p_{\theta}(\mathbf{z})-\log q_{\phi}(\mathbf{z} | \mathbf{x})\right]
\end{aligned}
\]</span> 通常采用蒙特卡罗积分来近似上式方程中的期望，如下式。 <span class="math display">\[
\mathbb{E}_{q_{\phi}(\mathbf{z} | \mathbf{x})}[f(\mathbf{z})] \approx \frac{1}{L} \sum_{l=1}^{L} f\left(\mathbf{z}^{(l)}\right)
\]</span> 其中，<span class="math inline">\(\mathbf{z}^{(l)}, l=1,2,\cdots, L\)</span> 是 <span class="math inline">\(q_{\phi}(\mathbf{z})\)</span> 中的采样。</p>
<h2 id="donut">Donut</h2>
<h3 id="网络结构">网络结构</h3>
<p>总体架构如图 3 所示，其中三个关键技术分别是改进的 ELBO、训练中插入丢失数据以及检测中的 MCMC 插补。</p>
<p><img src="https://cdn.jsdelivr.net/gh/davidlight2018/figure_bed/img/2020-04-27_17-07-44.png" style="zoom:40%;" /></p>
<p>本文研究的 KPI 假定为具有高斯噪声的时间序列。但是，VAE 不是顺序模型，因此我们在 KPI 上应用长度为 <span class="math inline">\(W\)</span> 的滑动窗口：对于每个点 <span class="math inline">\(x_t\)</span>，我们用 <span class="math inline">\(x_{t-W+1}, \cdots, x_t\)</span> 来表示 VAE 中的 <span class="math inline">\(\mathbf{x}\)</span> 向量。</p>
<p>Donut 的整体网络结构如图 4 所示，其中带有双线轮廓的组件为新的设计。先验 <span class="math inline">\(p_{\theta}(\mathbf{z})\)</span> 为高斯分布 <span class="math inline">\(\mathcal{N}(0,I)\)</span>，<span class="math inline">\(\mathbf{x}\)</span> 和 <span class="math inline">\(\mathbf{z}\)</span> 的后验均选择为对角线高斯 <span class="math inline">\(p_{\theta}(\mathbf{x} | \mathbf{z})=\mathcal{N}\left(\boldsymbol{\mu}_{\mathbf{x}}, \boldsymbol{\sigma}_{\mathbf{x}}^{2} \mathbf{I}\right)\)</span> 和 <span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{x})=\mathcal{N}\left(\boldsymbol{\mu}_{\mathbf{z}}, \boldsymbol{\sigma}_{\mathbf{z}}^{2} \mathbf{I}\right)\)</span>，其中 <span class="math inline">\(\boldsymbol{\mu}_{\mathbf{x}}, \boldsymbol{\mu}_{\mathbf{z}}, \boldsymbol{\sigma}_{\mathbf{x}}, \boldsymbol{\sigma}_{\mathbf{z}}\)</span> 是每个独立高斯分量的均值和标准差。</p>
<p><span class="math inline">\(\mathbf{z}\)</span> 为 <span class="math inline">\(K\)</span> 维向量。 通过分离的隐藏层 <span class="math inline">\(f_{\phi}(\mathbf{x})\)</span> 和 <span class="math inline">\(f_{\theta}(\mathbf{z})\)</span> 并从 <span class="math inline">\(\mathbf{x}\)</span> 和 <span class="math inline">\(\mathbf{z}\)</span> 中提取隐藏特征，之后隐藏特征中得出 <span class="math inline">\(\mathbf{x}\)</span> 和 <span class="math inline">\(\mathbf{z}\)</span> 的高斯参数。</p>
<p>平均值来自线性层：<span class="math inline">\(\boldsymbol{\mu}_{\mathbf{x}}=\mathbf{W}_{\boldsymbol{\mu}_{\mathbf{x}}}^{\top} f_{\theta}(\mathbf{z})+\mathbf{b}_{\boldsymbol{\mu}_{\mathbf{x}}}\)</span> 和 <span class="math inline">\(\boldsymbol{\mu}_{\mathbf{z}}=\mathbf{W}_{\boldsymbol{\mu}_{z}}^{\top} f_{\phi}(\mathbf{x})+\mathbf{b}_{\boldsymbol{\mu}_{\mathbf{z}}}\)</span>；</p>
<p>标准差是从 Soft-Plus 层并加上一个非负小数 <span class="math inline">\(\epsilon\)</span> 得出：<span class="math inline">\(\sigma_{\mathrm{x}}=\operatorname{SoftPlus}\left[\mathbf{W}_{\sigma_{\mathrm{x}}}^{\top} f_{\theta}(\mathbf{z})+\mathbf{b}_{\sigma_{\mathrm{x}}}\right]+\epsilon\)</span> 以及 <span class="math inline">\(\sigma_{\mathrm{z}}=\operatorname{SoftPlus}\left[\mathbf{W}_{\sigma_{\mathrm{z}}}^{\top} f_{\theta}(\mathbf{x})+\mathbf{b}_{\sigma_{\mathrm{z}}}\right]+\epsilon\)</span>，其中 <span class="math inline">\(\operatorname{SoftPlus}[a] = \text{log}[\text{exp}(a)+1]\)</span>。所有的 <span class="math inline">\(\mathbf{W}\)</span> 和 <span class="math inline">\(\mathbf{b}\)</span> 都是相应层的参数。需要注意的是，标量函数 <span class="math inline">\(f(x)\)</span> 应用于向量 <span class="math inline">\(\mathbf{x}\)</span> 时，是应用在它的每个分量上的。</p>
<p><img src="https://cdn.jsdelivr.net/gh/davidlight2018/figure_bed/img/2020-04-27_17-13-23.png" style="zoom:40%;" /></p>
<p>我们选择以这种方法来导出 <span class="math inline">\(\boldsymbol{\sigma}_{\mathbf{x}}, \boldsymbol{\sigma}_{\mathbf{z}}\)</span>，而不是像其他人那样使用线性层来导出 <span class="math inline">\(\text{log}\boldsymbol{\sigma}_{\mathbf{x}}, \text{log}\boldsymbol{\sigma}_{\mathbf{z}}\)</span>，是因为我们感兴趣的 KPI 局部变化非常小，以至于 <span class="math inline">\(\boldsymbol{\sigma}_{\mathbf{x}}, \boldsymbol{\sigma}_{\mathbf{z}}\)</span> 可能非常接近于 0，从而使 <span class="math inline">\(\text{log}\boldsymbol{\sigma}_{\mathbf{x}}, \text{log}\boldsymbol{\sigma}_{\mathbf{z}}\)</span> 无界。而这种情况在计算高斯变量的可能性时，将导致严重的数值问题。因此，我们使用 soft-plus 和 <span class="math inline">\(\epsilon\)</span> 技巧来避免此类问题。之后使用修改的 ELBO（M-ELBO）来排除异常点和缺失点的影响。</p>
<h3 id="训练">训练</h3>
<p>训练过程很直接，通过使用 SGVB 算法来优化 ELBO。当使用 SGVB 算法训练 VAE 时，一个样本足以计算 ELBO，因此在训练期间让采样数 <span class="math inline">\(L=1\)</span>。<span class="math inline">\(\mathbf{x}\)</span> 的窗口在每个训练轮次之前随机打乱，这对随机梯度下降很有用。在每个小批量训练中要使用足够多的 <span class="math inline">\(\mathbf{x}\)</span>，这对于训练的稳定性至关重要，因为采样会引入额外的随机性。</p>
<p>基于 VAE 的异常检测通过学习正常模式来工作，因此我们需要尽可能避免学习到异常模式。尝试用拟合值来替换数据中的标记异常（如果有）和缺失点（已知）是一种方法，先前的一些工作<sup id="a1"><a href="#f1">1</a></sup>提出了填补缺失数据的方法，但是很难产生足够好的遵循「正常模式的数据」。更重要的是，用另一种算法生成的数据来训练生成模型是很荒谬的，因为生成模型的一个主要应用就是生成数据，使用比 VAE 更弱的算法估算的数据可能会降低性能。因此，我们不会在训练 VAE 之前填补缺失数据，而是简单地将缺失点填充为零（在图 3 的准备步骤中）。更确切地说，我们将 ELBO 的标准公式修改为如下公式： <span class="math display">\[
\widetilde{\mathcal{L}}(\mathbf{x})=\mathbb{E}_{q_{\phi}(\mathrm{z} | \mathbf{x})}\left[\sum_{w=1}^{W} \alpha_{w} \log p_{\theta}\left(x_{w} | \mathbf{z}\right)+\beta \log p_{\theta}(\mathbf{z})-\log q_{\phi}(\mathbf{z} | \mathbf{x})\right]
\]</span> 其中，<span class="math inline">\(\alpha_{w}\)</span> 是一个指标，<span class="math inline">\(\alpha_{w}=1\)</span> 表示 <span class="math inline">\(x_w\)</span> 没有异常或缺失，否则 <span class="math inline">\(\alpha_{w}=0\)</span>；<span class="math inline">\(\beta\)</span> 定义为 <span class="math inline">\(\left(\sum_{w=1}^{W} \alpha_{w}\right) / W\)</span>。当训练数据中没有标记的异常时，上述公式仍然成立。<span class="math inline">\(a_w\)</span> 直接排除了来自标记异常点和缺失点的 <span class="math inline">\(p_{\theta}(x_{w} | \mathbf{z})\)</span> 的贡献，而缩放因子 <span class="math inline">\(\beta\)</span> 根据 <span class="math inline">\(\mathbf{x}\)</span> 中正常点的比例来缩小 <span class="math inline">\(p_{\theta}(\mathbf{z})\)</span> 的贡献。即使 <span class="math inline">\(\mathbf{x}\)</span> 中存在某些异常点，这样的修改能够使得 Donut 正确地重建 <span class="math inline">\(\mathbf{x}\)</span> 中的正常点。我们不缩小 <span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span> 基于以下两点考虑：(1) 与作为生成网络（即「正常模式」的模型）中一部分的 <span class="math inline">\(p_{\theta}(\mathbf{z})\)</span> 不同，<span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span> 仅描述了 <span class="math inline">\(\mathbf{x}\)</span> 到 <span class="math inline">\(\mathbf{z}\)</span> 的映射，而不考虑「正常模式」。因此，似乎没有必要去掉 <span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span> 的贡献；(2) 另一个原因是 <span class="math inline">\(\mathbb{E}_{q_{\phi}(\mathbf{z} | \mathbf{x})}\left[-\log q_{\phi}(\mathbf{z} | \mathbf{x})\right]\)</span> 恰好是 <span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span> 的熵，在训练中还有其他作用，因此最好保持不变。</p>
<p>处理异常和缺失点的另一种方法是从训练数据中排除所有包含这些点的窗口。事实证明，这种方法不如 M-ELBO。此外，我们还在训练中引入注入缺失数据的方法：我们以随机概率 <span class="math inline">\(\lambda\)</span> 将正常点设置为零，就好像它们是缺失点一样。缺失点更多，当给定异常 <span class="math inline">\(\mathbf{x}\)</span> 时，会更频繁的训练 Donut 来重建正常点，从而增强 M-ELBO 的效果。该注入会在每个训练轮次之前都执行，然后在轮次结束后将这些注入恢复。图 3 的训练阶段显示了注入缺失数据的过程。</p>
<h3 id="检测">检测</h3>
<p>诸如 VAE 的生成模型可以得出各种输出。在异常检测的范围内，观察窗口 <span class="math inline">\(\mathbf{x}\)</span> 的可能性（即 VAE 中的 <span class="math inline">\(p_{\theta}(\mathbf{x})\)</span>）是一个重要的输出，因为我们想知道给定 <span class="math inline">\(\mathbf{x}\)</span> 遵循正常模式的程度。我们可以使用蒙特卡罗方法计算 <span class="math inline">\(\mathbf{x}\)</span> 的概率密度，通过 <span class="math inline">\(p_{\theta}(\mathbf{x})=\mathbb{E}_{p_{\theta}(\mathbf{z})}\left[p_{\theta}(\mathbf{x} | \mathbf{z})\right]\)</span>。尽管在理论上有很好的解释性，但实际上，对先验样本进行采样并不能很好地完成工作。</p>
<p>人们可能会寻求通过计算后验 <span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span> 来获得有用的输出来替代在先验上采样，其中一种选择是计算等式 <span class="math inline">\(\mathbb{E}_{q_{\phi}(\mathbf{z} | \mathbf{x})}\left[p_{\theta}(\mathbf{x} | \mathbf{z})\right]\)</span>。尽管它与 <span class="math inline">\(p_{\theta}(\mathbf{x})\)</span> 相似，但它不是明确定义的概率密度。另一种选择是计算公式 ，称为<span class="math inline">\(\mathbb{E}_{q_{\phi}(\mathbf{z} | \mathbf{x})}\left[\log p_{\theta}(\mathbf{x} | \mathbf{z})\right]\)</span>「重建概率」。这两个选择非常相似，由于在异常检测中，我们只关注异常评分的顺序而不是确切值，因此我们遵循第二种方法。或者，使用 ELBO 等式也可以用于近似 <span class="math inline">\(\log p_\theta(\mathbf{x})\)</span>，但是等式中额外的部分 <span class="math inline">\(\mathbb{E}_{q_{\phi}(\mathbf{z} | \mathbf{x})}\left[\log p_{\theta}(\mathbf{z})-\log q_{\phi}(\mathbf{z} | \mathbf{x})\right]\)</span> 使其内部机制难以理解。而且，实验不支持该替代方案的优越性，因此我们选择不使用它。</p>
<p>在检测期间，测试窗口 <span class="math inline">\(\mathbf{x}\)</span> 中的异常和缺失点可能给映射 <span class="math inline">\(\mathbf{z}\)</span> 带来偏差，并进一步使得重建概率不准确。由于缺失点总是已知的，即「null」，因此我们有机会消除缺失点带来的偏差。我们选择训练好的 VAE 并使用基于 MCMC 的缺失数据插补技术。</p>
<p>另一方面，由于我们不知道异常在检测之前的确切位置，因此无法对异常采用 MCMC。更具体地说，我们将测试 <span class="math inline">\(\mathbf{x}\)</span> 分为观察到的部分和缺失部分连个部分，即 <span class="math inline">\((\mathbf{x}_{o}, \mathbf{x}_{m})\)</span>。从 <span class="math inline">\(q_{\phi}\left(\mathbf{z} | \mathbf{x}_{o}, \mathbf{x}_{m}\right)\)</span> 中获得样本 <span class="math inline">\(\mathbf{z}\)</span>，然后从 <span class="math inline">\(p_{\theta}\left(\mathbf{x}_{o}, \mathbf{x}_{m} | \mathbf{z}\right)\)</span> 中获得重构样本 <span class="math inline">\(\left(\mathbf{x}_{o}^{\prime}, \mathbf{x}_{m}^{\prime}\right)\)</span>。然后将 <span class="math inline">\((\mathbf{x}_{o}, \mathbf{x}_{m})\)</span> 替换为 <span class="math inline">\(\left(\mathbf{x}_{o}, \mathbf{x}_{m}^{\prime}\right)\)</span>，即观察点固定，缺失点设置为新值。将该过程重复 M 次，然后将最终值 <span class="math inline">\(\left(\mathbf{x}_{o}, \mathbf{x}_{m}^{\prime}\right)\)</span> 用于计算重建概率。在整个过程中，中间值 <span class="math inline">\(\mathbf{x}_{m}^{\prime}\)</span> 会越来越接近正常值。给定足够大的 M，可以减少偏差，并且可以获得更准确的重构概率。</p>
<p><img src="https://cdn.jsdelivr.net/gh/davidlight2018/figure_bed/img/2020-04-28_10-53-49.png" style="zoom:40%;" /></p>
<p>在 MCMC 之后，我们取 <span class="math inline">\(L\)</span> 个 <span class="math inline">\(\mathbf{z}\)</span> 样本，通过蒙特卡罗积分来计算重建概率。尽管我们可以计算 <span class="math inline">\(\mathbf{x}\)</span> 的每个窗口中的每个点的重建概率，但我们只使用最后一个点的分数（即 <span class="math inline">\(x_{t-T+1}, \cdots, x_t\)</span> 中的 <span class="math inline">\(x_t\)</span>），因为我们想要在检测过程中越快的对异常作出响应。在之后的内容中，我们仍将使用矢量符号，与 VAE 的体系结构相对应。</p>
<h2 id="实验评估">实验评估</h2>
<h3 id="数据集">数据集</h3>
<p>选择了 3 个数据集，如图 1 所示。数据集 A、B 和 C 分别具有小、中、大的噪声（曲线 A 最为平滑）。</p>
<p><img src="https://cdn.jsdelivr.net/gh/davidlight2018/figure_bed/img/2020-04-28_13-46-51.png" style="zoom:50%;" /></p>
<p>在我们的评估中，我们完全忽略了所有算法在缺失点（null）的输出，会对其他所有点计算一个异常分数。可以通过选择一个阈值来做出决定：如果某个点的得分大于阈值，则应该触发警报。</p>
<h3 id="参数设置">参数设置</h3>
<p>我们将滑动窗口大小 <span class="math inline">\(W\)</span> 设置为 120，在数据集中意味着 2 小时。<span class="math inline">\(W\)</span> 的选择受到两个因素的影响：(1) 太小的 <span class="math inline">\(W\)</span> 将导致模型无法捕获模式，因为模型期望从窗口中的信息中识别出正常模式；(2) 而 <span class="math inline">\(W\)</span> 太大则会增加过拟合的风险，因为我们保持完全连接层而不使用权重共享，因此模型的参数量与 <span class="math inline">\(W\)</span> 成正比。</p>
<p>隐藏层 <span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span> 和 <span class="math inline">\(p_{\theta}(\mathbf{x} | \mathbf{z})\)</span> 都选择使用两个具有 100 个单元的 ReLU 层，使得变分网络和生成网络具有相同的大小。我们没有对隐藏网络的结构进行详细的搜索。</p>
<p>对于 std 层我们设置 <span class="math inline">\(\epsilon=10^{-4}\)</span>，异常插入比率 <span class="math inline">\(\lambda=0.01\)</span>，MCMC 的迭代次数 <span class="math inline">\(M=10\)</span>，蒙特卡罗的采样数 <span class="math inline">\(L=1024\)</span>。训练的批大小设置为 256，并运行 250 个轮次。使用 Adam 优化器，其初始学习率为 <span class="math inline">\(10^{-3}\)</span>。每 10 个轮次，学习率会乘以 0.75 来降低。我们对隐藏层应用 L2 正则化，其系数为 <span class="math inline">\(10^{-3}\)</span>。对梯度进行裁剪（by norm？），限制为 10.0。</p>
<p>我们将测试 3 个版本的数据。</p>
<ul>
<li>0% 的标签，我们忽略数据集中所有的标签；</li>
<li>10% 的标签，我们对训练和验证集的异常标签进行下采样，以使其包含 10% 的标记异常。这里需要注意的事，缺失点不会进行下采样。我们会不断丢弃异常片段，其概率与每个片段的长度成正比，直到达到所需的下采样率为止。我们使用这种方法，而不是随机丢弃单个异常点，是因为 KPI 是时间序列，因此每个异常点都可能泄漏其相邻点的有关信息，从而导致性能被高估。这样的下采样完成 10 次。</li>
<li>100% 的标签。</li>
</ul>
<h3 id="实验结果">实验结果</h3>
<p><img src="https://cdn.jsdelivr.net/gh/davidlight2018/figure_bed/img/2020-04-28_14-13-12.png" style="zoom:40%;" /></p>
<p>单独的 M-ELBO 可以在 VAE 基准上做出大部分改进，它通过 Donut 的训练来适应 <span class="math inline">\(x\)</span> 中可能出现的异常点，并产生期望的输出结果。尽管对于生成模型来说很自然，但是训练 VAE 仅使用正常数据进行检测不是一种好习惯。</p>
<p>缺失数据注入技术是为增强 M-ELBO 的效果而设计的，实际上可以看作是一种数据增强的方法。实际上，如果我们不仅注入缺失点，而且在训练过程中综合注入异常，那会更好。然而，很难生成与真实异常足够相似的异常，这是一个大的话题，并且不在本文的讨论范围之内。引入缺失数据注入技术而带来的最佳 F 分数提高并不是很明显，并且在 B 和 C 标记为 0% 的数据集中，甚至表现比只使用 M-ELBO 还差一些。这很可能是因为，与仅使用 M-ELBO 的情况相比，注入会给训练带来额外的随机性，因此需要更大的训练时间。我们不确定采用注入需要运行多少时间，为了进行客观比较，在所有的情况下都使用相同的训练周期。我们仍建议使用缺失数据注入，即使需要付出较大的训练时间，因为它很有可能会起作用。</p>
<p>MCMC 也被设计于帮助 Donut 处理异常点，尽管 Donut 尽在某些情况下使用 MCMC 技术获得最佳 F 分数的显著提高，但它从未损害性能。因此，我们建议在检测中始终采用 MCMC。</p>
<p><span class="math inline">\(\mathbf{z}\)</span> 的维度，即 <span class="math inline">\(K\)</span> 的大小，起着重要的作用。<span class="math inline">\(K\)</span> 太小可能会导致拟合不足或次优平衡，另一方面，<span class="math inline">\(K\)</span> 太大可能会导致重建概率找不到好的后验概率。在完全无监督的情况下，很难选择一个好的 <span class="math inline">\(K\)</span>，因此我们将其留作未来的工作。在试验中，我们建议在 5-10 的范围内根据经验选择 <span class="math inline">\(K\)</span>。</p>
<h2 id="分析">分析</h2>
<h3 id="kde-解释">KDE 解释</h3>
<p>尽管在工作[2, 33]中采用了重建概率 <span class="math inline">\(\mathbb{E}_{q_{\phi}(\mathbf{z} | \mathbf{x})}\left[\log p_{\theta}(\mathbf{x} | \mathbf{z})\right]\)</span>，但尚不清楚其实际的工作方式。有人可能将其视为 <span class="math inline">\(\mathbb{E}_{q_{\phi}(\mathbf{z} | \mathbf{x})}\left[p_{\theta}(\mathbf{x} | \mathbf{z})\right]\)</span> 的变体，但是 <span class="math inline">\(\mathbb{E}_{q_{\phi}(\mathbf{z} | \mathbf{x})}\left[p_{\theta}(\mathbf{x} | \mathbf{z})\right]=\int p_{\theta}(\mathbf{x} | \mathbf{z}) q_{\phi}(\mathbf{z} | \mathbf{x}) \mathrm{d} \mathbf{z}\)</span> 绝不是一个明确定义的概率（通常，使用潜在的异常 <span class="math inline">\(x\)</span>，在给出后验 <span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span> 的情况下，计算 <span class="math inline">\(\log p_{\theta}(\mathbf{x} | \mathbf{z})\)</span>，并不能提供有用的信息）。因此，[2, 33] 中的任何一个都不能用概率框架来解释。我们在此提出对于重构概率和整个 Donut 算法的 KDE 解释。</p>
<blockquote>
<p>核密度估计（kernel density estimation, KDE）是在概率论中用来估计未知的密度函数，属于非参数检验方法之一。核密度估计在估计边界区域的时候会出现<a href="https://zh.wikipedia.org/w/index.php?title=边界效应&amp;action=edit&amp;redlink=1" target="_blank" rel="noopener">边界效应</a>。</p>
</blockquote>
<p><img src="https://cdn.jsdelivr.net/gh/davidlight2018/figure_bed/img/2020-05-09_14-40-43.png" style="zoom:40%;" /></p>
<p>如图 10(a) 所示，正常点 <span class="math inline">\(x\)</span> 的后验 <span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span> 呈现时间梯度。<span class="math inline">\(x\)</span> 的连续时间窗口（以下简称为连续 <span class="math inline">\(x\)</span>）映射到附近的 <span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span> ，且大多具有较小的方差 <span class="math inline">\(\sigma_z\)</span>（如图 11 所示）。<span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span> 以平滑过渡的方式组成，使得样本 <span class="math inline">\(z\)</span> 在图中显示出颜色梯度，我们将此结构称为「时间梯度」。本文的 KPI 总体上是平滑的，因此连续的 <span class="math inline">\(x\)</span> 非常相似。时间梯度是在 <span class="math inline">\(x\)</span> 的形状上 <span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span> 的过渡，是因为 Donut 仅消耗 <span class="math inline">\(x\)</span> 的形状而没有时间信息。时间梯度有利于 Donut 在未出现过的数据上一般化：如果我们在两个训练后验之间的某地方得到后验 <span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span>，它将有明确的定义，避免荒谬的检测结果。</p>
<p>对于部分异常的 <span class="math inline">\(x\)</span>，维度的减少将使 Donut 能够识别其正常模式 <span class="math inline">\(\tilde{x}\)</span>，并使 <span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span> 近似为 <span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{\tilde{x}})\)</span>。此效果是由于以下原因引起的。Donut 的训练会以最大努力来重建训练样本中的正常点，而维度的减少使得 Donut 仅能从 <span class="math inline">\(x\)</span> 中捕获少量信息。其结果是，只有整体的形状被编码为 <span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span>，在此过程中可能会丢失异常信息。但是，如果 <span class="math inline">\(x\)</span> 太异常的话，Donut 可能无法识别任何正常点 <span class="math inline">\(\tilde{x}\)</span>，从而使得 <span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span> 变得不明确。</p>
<p>部分异常 <span class="math inline">\(x\)</span> 的 <span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span> 与 <span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{\tilde{x}})\)</span> 相似的事实为 Donut 的重建概率带来了特殊的含义。因为在训练过程中，对于正常模式我们最大化 M-ELBO，因此对于 <span class="math inline">\(\mathbf{z} \sim q_{\phi}(\mathbf{z} | \tilde{\mathbf{x}})\)</span> 的 <span class="math inline">\(\log p_{\theta}(\mathbf{x} | \mathbf{z})\)</span>，在 <span class="math inline">\(x\)</span> 与 <span class="math inline">\(\tilde{x}\)</span> 相似的情况下，应该产生高分，反之亦然。也就是说，每个 <span class="math inline">\(\log p_{\theta}(\mathbf{x} | \mathbf{z})\)</span> 可以用作密度估计器，表示 <span class="math inline">\(x\)</span> 遵循正常模式 <span class="math inline">\(\tilde{x}\)</span> 的程度。然后，后验期望将所有的 <span class="math inline">\(\log p_{\theta}(\mathbf{x} | \mathbf{z})\)</span> 得分相加，并对每个 <span class="math inline">\(z\)</span> 赋予权重 <span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span>。该过程与加权核密度估计非常相似[11, 14]，因此，我们进行了 KDE 解释：可以将 Donut 中的重建概率 <span class="math inline">\(\mathbb{E}_{q_{\phi}(\mathbf{z} | \mathbf{x})}\left[\log p_{\theta}(\mathbf{x} | \mathbf{z})\right]\)</span> 视为加权核密度估计，其中 <span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span> 为权重，<span class="math inline">\(\log p_{\theta}(\mathbf{x} | \mathbf{z})\)</span> 作为内核（权重 <span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span> 通过蒙特卡罗积分中的采样隐式应用）。图 11 是 KDE 解释的说明，从 KDE 的解释中，我们怀疑采用任何技术的先验期望都不能很好地工作，对先验采样应该获得 <span class="math inline">\(x\)</span> 所有模式的核，可能会混淆特定 <span class="math inline">\(x\)</span> 的密度估计。</p>
<p><img src="https://cdn.jsdelivr.net/gh/davidlight2018/figure_bed/img/2020-05-09_15-21-15.png" /></p>
<center style="font-size:14px;color:#808080;text-decoration:underline">
图11. KDE解释说明
</center>
<p>对于给定的、可能存在异常的 <span class="math inline">\(x\)</span>，Donut尝试识别其遵循的正常模式，编码为 。中间的黑色椭圆表示 图11. 对于给定的、可能存在异常的 <span class="math inline">\(x\)</span>，Donut尝试识别其遵循的正常模式，编码为 <span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span> 的 3-<span class="math inline">\(\sigma_z\)</span> 区域。然后从 <span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span> 中获取 <span class="math inline">\(z\)</span> 的 <span class="math inline">\(L\)</span> 个样本，在椭圆中间的图中用叉号表示。每个 <span class="math inline">\(z\)</span> 与密度估计器内核 <span class="math inline">\(\log p_{\theta}(\mathbf{x} | \mathbf{z})\)</span> 相关联。右边两个图中的蓝色曲线是每个内核的 <span class="math inline">\(\mu_x\)</span>，而周围的条纹是 <span class="math inline">\(\sigma_x\)</span>，最后从每个内核计算 <span class="math inline">\(\log p_{\theta}(\mathbf{x} | \mathbf{z})\)</span> 的值，并将其进一步平均在一起作为重构概率。</p>
<p>Donut 可以识别出部分异常 <span class="math inline">\(x\)</span> 的正常模式，并找到一个很好的后验来评估 <span class="math inline">\(x\)</span> 遵循正常模式的程度。</p>
<h3 id="时间梯度的原因">时间梯度的原因</h3>
<p>在本节中，我们讨论时间梯度效应的原因。为了简化讨论，我们假设训练 <span class="math inline">\(x\)</span> 都是正常的，因此 M-ELBO 现在相当于原始的 ELBO。M-ELBO 可以分解为如下等式中的三个项： <span class="math display">\[
\begin{aligned}
\mathcal{L}(\mathbf{x}) &amp;=\mathbb{E}_{q_{\phi}(\mathbf{z} | \mathbf{x})}\left[\log p_{\theta}(\mathbf{x} | \mathbf{z})+\log p_{\theta}(\mathbf{z})-\log q_{\phi}(\mathbf{z} | \mathbf{x})\right] \\
&amp;=\mathbb{E}\left[\log p_{\theta}(\mathbf{x} | \mathbf{z})\right]+\mathbb{E}\left[\log p_{\theta}(\mathbf{z})\right]+\mathrm{H}[\mathbf{z} | \mathbf{x}]
\end{aligned}
\]</span> 第一项要求 <span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span> 中的 <span class="math inline">\(z\)</span> 个样本具有重构 <span class="math inline">\(x\)</span> 的高可能性，其结果为，对于形状不相同的 <span class="math inline">\(x\)</span> 的 <span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span> 被分离了。第二项使 <span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span> 集中于 <span class="math inline">\(\mathcal{N}(\mathbf{0}, \mathbf{I})\)</span>。第三项，即 <span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span> 的熵，使得 <span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span> 尽可能扩大。回想一下，第二项为 <span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span> 设置了扩展的限制区域（关于第二项和第三项的组合效果，请参见图 10c）。考虑到第一项，如果两个不同的 <span class="math inline">\(x\)</span> 的 <span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span> 彼此达到一起，则扩展也将停止。为了使每个 <span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span> 在训练收敛时具有最大的范围（即这三项达到平衡），相似的 <span class="math inline">\(x\)</span> 必须彼此靠近，从而使 <span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span> 扩大边界的重叠。由于连续的 <span class="math inline">\(x\)</span> 在季节性 KPI 中相似（反之亦然），因此如果可以实现这种平衡，时间梯度将是自然的结果。</p>
<p><img src="https://cdn.jsdelivr.net/gh/davidlight2018/figure_bed/img/2020-05-09_16-25-48.png" style="zoom:50%;" /></p>
<p>接下来，我们讨论如何实现这种平衡。如图 14 所示，SGVB 算法在训练过程中不断推开相异的 <span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span>。两个 <span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span> 相异越多，它们被推的越远。因为我们随机地初始化了变分网络，所以当训练刚开始时，<span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span> 随处可见，如图 10(b) 所示。此时，每个 <span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span> 都被其他所有的 <span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span> 推开。由于 <span class="math inline">\(x\)</span> 是 KPI 的滑动窗口，因此时间上相隔深远的 <span class="math inline">\(x\)</span> 通常会更不相似，因此彼此之间的距离会越来越远。这为 <span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span> 提供了初始布局。随着训练的进行，时间梯度将被微调并逐渐建立，如图 15(a) 所示。学习速率退火技术非常重要，因为它可以逐渐稳定布局。令人惊讶的是，我们在 M-ELBO 中找不到将任何相似 <span class="math inline">\(x\)</span> 直接拉在一起的项。时间梯度可能主要由于扩张（<span class="math inline">\(\mathrm{H}[\mathbf{z} | \mathbf{x}]\)</span>）、压缩（<span class="math inline">\(\mathbb{E}\left[\log p_{\theta}(\mathbf{z})\right]\)</span>）、推动（<span class="math inline">\(\mathbb{E}\left[\log p_{\theta}(\mathbf{x} | \mathbf{z})\right]\)</span>）和训练动力学（随机初始化和 SGVB）。这有时可能会引起麻烦，并导致布局欠佳，如图 15(b) 所示。</p>
<p><img src="/Users/david/Library/Application Support/typora-user-images/image-20200509164754783.png" alt="image-20200509164754783" style="zoom:50%;" /></p>
<h3 id="次优平衡">次优平衡</h3>
<p><span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span> 有时会收敛到次优平衡，在最初的 100 步之后，紫色点偶然穿过绿色点。紫色点将绿色点推向两侧，导致绿色点在大约 500 步处被完全切除。随着训练的进行，绿色点将被进一步推动，使得模型被锁定在该次优均衡状态，并且永远无法逃脱。<span class="math inline">\(z\)</span> 的这种不好的布局破坏了时间梯度，其中遵循绿色模式的测试 <span class="math inline">\(x\)</span> 可能会意外地映射到两个绿色部分之间的某个位置，并被识别为紫色。根据 KDE 的解释，这肯定会降低检测性能。当存在未标记的异常时「anomalies」，训练将变得不稳定，因此该模型可能会意外地脱离次优平衡状态，然后达到更好地平衡状态。如果在训练中使用 early-stopping，最好平衡将被最终选择。这就解释了为什么有时候具有完整的标签不会使性能受益。对于较大的 <span class="math inline">\(K\)</span>，此效果可能不太明显，因为具有较大的维度会给 <span class="math inline">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span> 额外的自由生长空间，从而减少不良布局的可能性。当次优均衡不是关键问题时，训练的收敛性就变得更加重要，而拥有更多标签肯定有助于稳定训练。总之，只要 <span class="math inline">\(K\)</span> 足够大，在 Donut 中使用异常标签很可能会提高性能。</p>
<h2 id="reference">Reference</h2>
<p><b id="f1">[1]:</b> Jonathan AC Sterne, Ian R White, John B Carlin, Michael Spratt, Patrick Royston, Michael G Kenward, Angela M Wood, and James R Carpenter. 2009. Multiple imputation for missing data in epidemiological and clinical research: potential and pitfalls. Bmj 338 (2009), b2393. <a href="#a1">↩</a></p>

  </div>
</article>

    <div class="blog-post-comments">
        <div id="disqus_thread">
            <noscript>Please enable JavaScript to view the comments.</noscript>
        </div>
    </div>



        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/tags/">Tags</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/search/">Search</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#背景介绍"><span class="toc-number">1.</span> <span class="toc-text">背景介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#变分自编码器简介"><span class="toc-number">2.</span> <span class="toc-text">变分自编码器简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#donut"><span class="toc-number">3.</span> <span class="toc-text">Donut</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#网络结构"><span class="toc-number">3.1.</span> <span class="toc-text">网络结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#训练"><span class="toc-number">3.2.</span> <span class="toc-text">训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#检测"><span class="toc-number">3.3.</span> <span class="toc-text">检测</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#实验评估"><span class="toc-number">4.</span> <span class="toc-text">实验评估</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#数据集"><span class="toc-number">4.1.</span> <span class="toc-text">数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#参数设置"><span class="toc-number">4.2.</span> <span class="toc-text">参数设置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#实验结果"><span class="toc-number">4.3.</span> <span class="toc-text">实验结果</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#分析"><span class="toc-number">5.</span> <span class="toc-text">分析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#kde-解释"><span class="toc-number">5.1.</span> <span class="toc-text">KDE 解释</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#时间梯度的原因"><span class="toc-number">5.2.</span> <span class="toc-text">时间梯度的原因</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#次优平衡"><span class="toc-number">5.3.</span> <span class="toc-text">次优平衡</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#reference"><span class="toc-number">6.</span> <span class="toc-text">Reference</span></a></li></ol>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" href="http://www.facebook.com/sharer.php?u=http://blog.tsinghua2018.top/2020/04/26/www18_donut/" target="_blank" rel="noopener"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://twitter.com/share?url=http://blog.tsinghua2018.top/2020/04/26/www18_donut/&text=『阅读笔记』Unsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal KPIs inWeb Applications" target="_blank" rel="noopener"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.linkedin.com/shareArticle?url=http://blog.tsinghua2018.top/2020/04/26/www18_donut/&title=『阅读笔记』Unsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal KPIs inWeb Applications" target="_blank" rel="noopener"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=http://blog.tsinghua2018.top/2020/04/26/www18_donut/&is_video=false&description=『阅读笔记』Unsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal KPIs inWeb Applications" target="_blank" rel="noopener"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=『阅读笔记』Unsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal KPIs inWeb Applications&body=Check out this article: http://blog.tsinghua2018.top/2020/04/26/www18_donut/"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://getpocket.com/save?url=http://blog.tsinghua2018.top/2020/04/26/www18_donut/&title=『阅读笔记』Unsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal KPIs inWeb Applications" target="_blank" rel="noopener"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://reddit.com/submit?url=http://blog.tsinghua2018.top/2020/04/26/www18_donut/&title=『阅读笔记』Unsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal KPIs inWeb Applications" target="_blank" rel="noopener"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.stumbleupon.com/submit?url=http://blog.tsinghua2018.top/2020/04/26/www18_donut/&title=『阅读笔记』Unsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal KPIs inWeb Applications" target="_blank" rel="noopener"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://digg.com/submit?url=http://blog.tsinghua2018.top/2020/04/26/www18_donut/&title=『阅读笔记』Unsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal KPIs inWeb Applications" target="_blank" rel="noopener"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.tumblr.com/share/link?url=http://blog.tsinghua2018.top/2020/04/26/www18_donut/&name=『阅读笔记』Unsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal KPIs inWeb Applications&description=" target="_blank" rel="noopener"><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://news.ycombinator.com/submitlink?u=http://blog.tsinghua2018.top/2020/04/26/www18_donut/&t=『阅读笔记』Unsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal KPIs inWeb Applications" target="_blank" rel="noopener"><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fas fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fas fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy;
    
    
    2020
    David
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/tags/">Tags</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/search/">Search</a></li>
        
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->

<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">


<link rel="stylesheet" href="/lib/justified-gallery/css/justifiedGallery.min.css">


    <!-- jquery -->

<script src="/lib/jquery/jquery.min.js"></script>


<script src="/lib/justified-gallery/js/jquery.justifiedGallery.min.js"></script>

<!-- clipboard -->

  
<script src="/lib/clipboard/clipboard.min.js"></script>

  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="far fa-clone"></i>';
    btn += '</span>'; 
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>


<script src="/js/main.js"></script>

<!-- search -->

<!-- Google Analytics -->

<!-- Baidu Analytics -->

<!-- Disqus Comments -->

    <script type="text/javascript">
        var disqus_shortname = 'davids-blog-6';

        (function(){
            var dsq = document.createElement('script');
            dsq.type = 'text/javascript';
            dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        }());
    </script>


    
    

        

        
            <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css" crossorigin="anonymous">
            <script defer src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js" crossorigin="anonymous"></script>
            <script
                    defer
                    src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/auto-render.min.js"
                    crossorigin="anonymous"
                    onload="renderMathInElement(document.body)">
            </script>
        

    

</body>
</html>
